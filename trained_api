from flask import Flask, request, jsonify, send_from_directory
from diffusers import StableDiffusionPipeline, StableVideoDiffusionPipeline
from moviepy import ImageSequenceClip
from PIL import Image
import torch, uuid, os

app = Flask(__name__, static_folder="static", static_url_path="/static")

# Load SD with LoRA
sd_pipe = StableDiffusionPipeline.from_pretrained(
    "/home/ubuntu/money-leads-video-generator/peter_model/final_model_peter",
    torch_dtype=torch.float32
).to("cuda")

# Load SVD pipeline (for motion generation)
svd_pipe = StableVideoDiffusionPipeline.from_pretrained(
    "stabilityai/stable-video-diffusion-img2vid",
    torch_dtype=torch.float16,
    variant="fp16"
).to("cuda")

@app.route("/")
def home():
    return send_from_directory("static", "index.html")

@app.route("/generate", methods=["POST"])
def generate_video():
    os.makedirs("static/generated", exist_ok=True)

    # Step 1: Generate image with LoRA SD
    prompt = "a person clapping hands"
    result = sd_pipe(prompt=prompt)
    image = result.images[0]
    
    # Save image
    temp_image_path = f"static/generated/{uuid.uuid4().hex}_image.png"
    image.save(temp_image_path)

    # Step 2: Convert image to motion using SVD
    image = image.resize((512, 512)).convert("RGB")
    frames = svd_pipe(image).frames  # returns list of PIL Images

    # Convert frames to video
    video_path = f"static/generated/{uuid.uuid4().hex}_video.mp4"
    clip = ImageSequenceClip(frames, fps=8)
    clip.write_videofile(video_path, codec="libx264")

    return jsonify({
        "image_url": f"/{temp_image_path}",
        "video_url": f"/{video_path}"
    })

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)
