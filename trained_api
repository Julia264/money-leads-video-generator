from flask import Flask, request, jsonify, send_from_directory
from diffusers import StableVideoDiffusionPipeline
import torch
from PIL import Image
import os
import uuid
from moviepy import ImageSequenceClip

app = Flask(__name__, static_folder="static", static_url_path="/static")

# Load trained video diffusion model
model_path = "/home/ubuntu/money-leads-video-generator/peter_model/final_model_peter"
pipe = StableVideoDiffusionPipeline.from_pretrained(
    model_path,
    torch_dtype=torch.float32,
    safety_checker=None,
    requires_safety_checker=False
).to("cuda" if torch.cuda.is_available() else "cpu")

@app.route("/")
def home():
    return send_from_directory("static", "index.html")

@app.route("/generate", methods=["POST"])
def generate_video():
    if 'image' not in request.files:
        return jsonify({"error": "No image uploaded"}), 400

    image_file = request.files['image']

    # ðŸ§  Fixed prompt: convert input to clapping
    prompt = "a person clapping hands"

    os.makedirs("static/uploads", exist_ok=True)
    os.makedirs("static/generated", exist_ok=True)

    # Save and process image
    input_path = f"static/uploads/{uuid.uuid4().hex}.png"
    image_file.save(input_path)
    image = Image.open(input_path).convert("RGB").resize((512, 512))

    # Generate motion (frames)
    video_frames = pipe(prompt=prompt, image=image).frames

    # Convert to video
    video_filename = f"{uuid.uuid4().hex}.mp4"
    output_path = f"static/generated/{video_filename}"

    clip = ImageSequenceClip(video_frames, fps=8)
    clip.write_videofile(output_path, codec="libx264")

    return jsonify({
        "video_url": f"/static/generated/{video_filename}"
    })

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)
